---
title: "Nested EnVar with cross covariance"
format:
  html:
    code-fold: true
    code-tools: true
jupyter: python3
editor:
  render-on-save: true
---

```{python}
import numpy as np
import numpy.linalg as la
import matplotlib.pyplot as plt
from pathlib import Path
```

# Formulation
```{=tex}
\begin{align*}
J(\mathbf{w})&=
\frac{1}{2}
\begin{bmatrix}
\begin{pmatrix}
\mathbf{0}\\\mathbf{d}^\mathrm{v}
\end{pmatrix}
-
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}
\mathbf{w}
\end{bmatrix}^\mathrm{T}
\begin{pmatrix}
\mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
\mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
\end{pmatrix}^{-1}
\begin{bmatrix}
\begin{pmatrix}
\mathbf{0}\\\mathbf{d}^\mathrm{v}
\end{pmatrix}
-
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}
\mathbf{w}
\end{bmatrix}
+\frac{1}{2}(\mathbf{d}^\mathrm{o}-\mathbf{Y}^\mathrm{b}\mathbf{w})^\mathrm{T}\mathbf{R}^{-1}(\mathbf{d}^\mathrm{o}-\mathbf{Y}^\mathrm{b}\mathbf{w})\\
&=\frac{1}{2}
\begin{bmatrix}
\begin{pmatrix}
\mathbf{0}\\\mathbf{d}^\mathrm{v}
\end{pmatrix}
-
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}
\mathbf{w}
\end{bmatrix}^\mathrm{T}
\begin{bmatrix}
\tilde{\mathbf{d}}^\mathrm{v}
-
\tilde{\mathbf{X}}^\mathrm{b}
\mathbf{w}
\end{bmatrix}
+\frac{1}{2}(\mathbf{d}^\mathrm{o}-\mathbf{Y}^\mathrm{b}\mathbf{w})^\mathrm{T}\mathbf{R}^{-1}(\mathbf{d}^\mathrm{o}-\mathbf{Y}^\mathrm{b}\mathbf{w})
\end{align*}
```

```{=tex}
\begin{align*}
\nabla_\mathbf{w}J&=
\left[
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}^\mathrm{T}
\begin{pmatrix}
    \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
    \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
\end{pmatrix}^{-1}
\begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\
    \mathbf{Z}^\mathrm{b}
\end{pmatrix}
+(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{Y}^\mathrm{b}
\right]\mathbf{w}
-
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}^\mathrm{T}
\begin{pmatrix}
    \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
    \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
    \end{pmatrix}^{-1}
    \begin{pmatrix}
    \mathbf{0}\\
    \mathbf{d}^\mathrm{v}
\end{pmatrix}
-(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{d}^\mathrm{o}\\
&=\underbrace{\left[
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}^\mathrm{T}
\tilde{\mathbf{X}}^\mathrm{b}
+(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{Y}^\mathrm{b}
\right]}_{\nabla^2_\mathbf{w}J}
\mathbf{w}
-
\begin{pmatrix}
\mathbf{X}^\mathrm{b}\\
\mathbf{Z}^\mathrm{b}
\end{pmatrix}^\mathrm{T}
\tilde{\mathbf{d}}^\mathrm{v}
-(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{d}^\mathrm{o}
=0
\end{align*}
```

$$
\begin{pmatrix}
    \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
    \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
\end{pmatrix}\tilde{\mathbf{X}}^\mathrm{b}
=
\begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\
    \mathbf{Z}^\mathrm{b}
\end{pmatrix}
$$

$$
\begin{pmatrix}
    \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
    \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
\end{pmatrix}\tilde{\mathbf{d}}^\mathrm{v}
=
\begin{pmatrix}
\mathbf{0}\\\mathbf{d}^\mathrm{v}
\end{pmatrix}
$$

$$
\begin{pmatrix}
\mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
\mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
\end{pmatrix}
= \frac{1}{K-1}
\begin{pmatrix}
\mathbf{X}^\mathrm{b} \\
\mathbf{Z}^\mathrm{v}
\end{pmatrix}
\begin{bmatrix}
(\mathbf{X}^\mathrm{b})^\mathrm{T} &
(\mathbf{Z}^\mathrm{v})^\mathrm{T}
\end{bmatrix}
$$

```{python}
def cost(w,*args):
    Xb, Yb, Zb, do, dv, Xb_, dv_ = args
    nens = Xb.shape[1]
    tmp1 = np.hstack((np.zeros(Xb.shape[0]),dv-Zb@w))
    tmp2 = dv_ - Xb_ @ w
    tmp3 = do - Yb @ w # R=I
    return 0.5*(np.dot(tmp1,tmp2)+np.dot(tmp3,tmp3))

def solve(*args):
    Xb, Yb, Zb, do, dv, Xb_, dv_ = args
    nens = Xb.shape[1]
    hess = np.hstack((Xb.T,Zb.T)) @ Xb_ + Yb.T @ Yb # R=I
    rhs = np.hstack((Xb.T,Zb.T)) @ dv_ + Yb.T @ do
    w = la.solve(hess,rhs)

    # update ensemble prtb
    lam, c = la.eigh(hess)
    ndof = np.sum(lam>1.0e-10)
    if ndof < lam.size:
        D = np.diag(np.hstack((np.zeros(lam.size-ndof),1.0/np.sqrt(lam[lam.size-ndof:]))))
    else:
        D = np.diag(1.0/np.sqrt(lam))
    
    trans = c @ D @ c.T
    return w, trans
```

# Example

```{python}
datadir = Path(f'/Volumes/nakashita/Development/pydpac/work/l05nestm/envar_nestc_shrink_preGM_m80obs30/data')
def loaddata(icycle,pt):
    Xb = np.load(datadir/f"{pt}/l05nestm_lam_spf_linear_{pt}_cycle{icycle}.npy")
    nmem = Xb.shape[1]
    Xb *= np.sqrt(nmem-1)
    Zv = np.load(datadir/f"{pt}/l05nestm_lam_zvmat_linear_{pt}_cycle{icycle}.npy")
    Zb = np.load(datadir/f"{pt}/l05nestm_lam_zbmat_linear_{pt}_cycle{icycle}.npy")
    dv = np.load(datadir/f"{pt}/l05nestm_lam_dk_linear_{pt}_cycle{icycle}.npy")
    Yb = np.load(datadir/f"{pt}/l05nestm_lam_dh_linear_{pt}_cycle{icycle}.npy")
    do = np.load(datadir/f"{pt}/l05nestm_lam_d_linear_{pt}_cycle{icycle}.npy")
    # debug
    dx = np.load(datadir/f"{pt}/l05nestm_lam_dx_linear_{pt}_cycle{icycle}.npy")
    dx_conv = np.load(datadir/f"envar/l05nestm_lam_dx_linear_envar_cycle{icycle}.npy")
    Xb_conv = np.load(datadir/f"envar/l05nestm_lam_spf_linear_envar_cycle{icycle}.npy")
    Xb_conv *= np.sqrt(nmem-1)
    Yb_conv = np.load(datadir/f"envar/l05nestm_lam_dh_linear_envar_cycle{icycle}.npy")
    do_conv = np.load(datadir/f"envar/l05nestm_lam_d_linear_envar_cycle{icycle}.npy")

    return Xb, Zb, Zv, Yb, do, dv, dx, dx_conv, Xb_conv, Yb_conv, do_conv

icycle=50
pt="envar_nest"
Xb, Zb, Zv, Yb, do, dv, dx, dx_conv, Xb_conv, Yb_conv, do_conv = loaddata(icycle,pt)
print(Xb.shape)
print(Zv.shape)
print(Zb.shape)
print(dv.shape)
print(Yb.shape)
print(do.shape)
print(dx.shape)
```

```{python}
#| fig-cap: ensemble perturbations
#| fig-subcap:
#|   - Xb
#|   - Zb, Zv, Yb
#| label: fig-ensprtb
#| layout: [[1,2],[1]]

fig, ax = plt.subplots()
mp0=ax.matshow(Xb)
fig.colorbar(mp0,ax=ax,shrink=0.6,pad=0.01)
ax.set_title('Xb')
plt.show()

fig2, axs = plt.subplots(nrows=3,constrained_layout=True)
axs[0].set_title('Zb')
mp1=axs[0].matshow(Zb)
axs[1].set_title('Zv')
mp2=axs[1].matshow(Zv)
axs[2].set_title('Yb')
mp3=axs[2].matshow(Yb)
for mp, ax in zip([mp1,mp2,mp3],axs):
    fig2.colorbar(mp,ax=ax,pad=0.01,shrink=0.6,orientation='horizontal')
plt.show()

```

```{python}
#| fig-cap: innovations
#| fig-subcap:
#|   - observation (d^o)
#|   - large-scale (d^v)
#| label: fig-innv
#| layout-ncol: 2

fig, ax = plt.subplots()
ax.plot(do,np.arange(do.size))
ax.set_xlabel('d^o')
ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
plt.show()

fig, ax = plt.subplots()
ax.plot(dv,np.arange(dv.size))
ax.set_xlabel('d^v')
ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
plt.show()

```

```{python}
#| fig-cap: ensemble error covariances
#| fig-subcap:
#|   - Pb
#|   - Pv
#|   - Pvb
#| label: fig-enserr-each
#| layout: [[3,2],[1]]

from matplotlib.colors import Normalize

nens = Xb.shape[1]
Pb = np.dot(Xb,Xb.transpose())/(nens-1)
Pbv = np.dot(Xb,Zv.transpose())/(nens-1)
Pvb = np.dot(Zv,Xb.transpose())/(nens-1)
Pv = np.dot(Zv,Zv.transpose())/(nens-1)

vlim = max(
    np.max(Pb),-np.min(Pb),
    np.max(Pbv),-np.min(Pbv),
    np.max(Pvb),-np.min(Pvb),
    np.max(Pv),-np.min(Pv)
)

fig, ax = plt.subplots()
mp0 = ax.matshow(Pb,cmap='coolwarm',norm=Normalize(vmin=-vlim,vmax=vlim))
fig.colorbar(mp0,ax=ax,shrink=0.6,pad=0.01)
ax.set_aspect('equal')
plt.show()
fig, ax = plt.subplots()
mp3 = ax.matshow(Pv,cmap='coolwarm',norm=Normalize(vmin=-vlim,vmax=vlim))
fig.colorbar(mp3,ax=ax,shrink=0.6,pad=0.01)
ax.set_aspect('equal')
plt.show()
fig, ax = plt.subplots()
mp2 = ax.matshow(Pvb,cmap='coolwarm',norm=Normalize(vmin=-vlim,vmax=vlim))
fig.colorbar(mp2,ax=ax,shrink=0.6,pad=0.01,orientation='horizontal')
ax.set_aspect(5)
plt.show()

```

```{python}
#| fig-cap: composite ensemble error covariance
#| label: fig-enserr

Pc = np.vstack((np.hstack((Pb,Pbv)),np.hstack((Pvb,Pv))))

fig, ax = plt.subplots()
mp = ax.matshow(Pc,cmap='coolwarm',norm=Normalize(-vlim,vlim))
fig.colorbar(mp,ax=ax,pad=0.01,shrink=0.6)
plt.show()
```

0. solution without cross covariance ($\mathbf{P}^\mathrm{bv}=\mathbf{P}^\mathrm{vb}=0$)

```{python}

    nens = Xb.shape[1]
    Xb_ = np.vstack(((nens-1)*np.eye(Xb.shape[1]),la.pinv(Pv)@Zb))
    dv_ = np.hstack((np.zeros(Xb.shape[1]),la.pinv(Pv)@dv))
    args = (np.eye(Xb.shape[1]), Yb, Zb, do, dv, Xb_, dv_)
    w_nc, trans_nc = solve(*args)
    Xa_nc = np.sqrt(nens-1)*Xb@trans_nc

    Ji = cost(np.zeros_like(w_nc),*args)
    Jf = cost(w_nc,*args)
    print(f"initial cost={Ji:.4e}")
    print(f"final cost={Jf:.4e}")

```
```{python}
    # without large-scale terms
    Xb_tmp = np.vstack(((nens-1)*np.eye(Xb.shape[1]),np.zeros_like(Zb)))
    dv_tmp = np.zeros_like(dv_)
    args_conv = (np.eye(Xb.shape[1]), Yb_conv, Zb, do_conv, dv, Xb_tmp, dv_tmp)
    w_conv, trans_conv = solve(*args_conv)
    Xa_conv = np.sqrt(nens-1)*Xb_conv@trans_conv

```

<!---
```{python}
#| fig-cap: solution without cross covariance
#| fig-subcap:
#|   - $\tilde{X}^b$
#|   - $\tilde{d}^b$
#| label: fig-nocross
#| layout: [[2,3],[1]]

    fig, ax = plt.subplots()
    mp=ax.matshow(Xb_)
    fig.colorbar(mp,ax=ax,pad=0.01,shrink=0.6)
    ax.set_aspect(0.5)
    plt.show()

    fig, ax = plt.subplots()
    ax.plot(dv_,np.arange(dv_.size))
    ax.set_xlabel(r'$\tilde{d}^v$')
    ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
    plt.show()
```

--->

```{python}
#| fig-cap: solution without cross covariance or without large-scale term
#| fig-subcap:
#|   - $\mathbf{w}$
#|   - $\delta\mathbf{x}$
#|   - Xb, Xa
#|   - $[\nabla^2 J]^{-1/2}$
#| label: fig-nocross-cost
#| layout: [[1,2],[1]]
    
    fig, ax = plt.subplots(figsize=[4,6])
    ax.plot(w_nc,np.arange(1,w_nc.size+1),label='no cross')
    ax.plot(w_conv,np.arange(1,w_nc.size+1),label='no V')
    xmin,xmax = ax.get_xlim()
    xlim = max(-xmin,xmax)
    ax.set_xlim(-xlim,xlim)
    ax.legend()
    ax.set_ylabel('member')
    ax.set_xlabel('w')
    plt.show()

    fig, ax = plt.subplots(figsize=[8,6])
    ax.plot(Xb@w_nc,label='nocross')
    #ax.plot(dx,ls='dashed')
    ax.plot(Xb@w_conv,label='no V')
    #ax.plot(dx_conv,ls='dashed')
    ymin,ymax = ax.get_ylim()
    ylim = max(-ymin,ymax)
    ax.set_ylim(-ylim,ylim)
    ax.legend()
    ax.set_xlabel('grid')
    ax.set_ylabel('dx')
    plt.show()

    fig, axs = plt.subplots(ncols=3,constrained_layout=True)
    mp0=axs[0].matshow(Xb)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('Xb')
    mp1=axs[1].matshow(Xa_nc)
    fig.colorbar(mp1,ax=axs[1],shrink=0.6,pad=0.01)
    axs[1].set_title('Xa (no cross)')
    mp2=axs[2].matshow(Xa_conv)
    fig.colorbar(mp2,ax=axs[2],shrink=0.6,pad=0.01)
    axs[2].set_title('Xa (no V)')
    plt.show()

    fig, axs = plt.subplots(ncols=2,constrained_layout=True)
    mp0=axs[0].matshow(trans_nc)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('trans (no cross)')
    mp1=axs[1].matshow(trans_conv)
    fig.colorbar(mp1,ax=axs[1],shrink=0.6,pad=0.01)
    axs[1].set_title('trans (no V)')
    plt.show()

```

1. pseudo-inverse (minimum-norm solution)
    $$
    \tilde{\mathbf{X}}^\mathrm{b}
    =
    \begin{pmatrix}
        \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
        \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
        \mathbf{X}^\mathrm{b}\\
        \mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    $$
    $$
    \tilde{\mathbf{d}}^\mathrm{v}
    =
    \begin{pmatrix}
        \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
        \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \mathbf{0}\\\mathbf{d}^\mathrm{v}
    \end{pmatrix}
    $$

```{python}

    Pcpinv = la.pinv(Pc,hermitian=True)
    Xb_ = Pcpinv @ np.vstack((Xb,Zb))
    dv_ = Pcpinv @ np.hstack((np.zeros(Xb.shape[0]),dv))
    
    args = (Xb, Yb, Zb, do, dv, Xb_, dv_)
    w, trans = solve(*args)
    Xa = np.sqrt(nens-1)*Xb@trans

    Ji = cost(np.zeros_like(w),*args)
    Jf = cost(w,*args)
    print(f"initial cost={Ji:.4e}")
    print(f"final cost={Jf:.4e}")

```

```{python}
#| fig-cap: minimum-norm solution
#| fig-subcap:
#|   - $\tilde{X}^b$
#|   - $\tilde{d}^b$
#| label: fig-minnorm
#| layout: [[2,3],[1]]

    fig, ax = plt.subplots()
    mp=ax.matshow(Xb_)
    fig.colorbar(mp,ax=ax,pad=0.01,shrink=0.6)
    ax.set_aspect(0.5)
    plt.show()

    fig, ax = plt.subplots()
    ax.plot(dv_,np.arange(dv_.size))
    ax.set_xlabel(r'$\tilde{d}^v$')
    ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
    plt.show()

```
```{python}
#| fig-cap: minimum-norm solution for $J$
#| fig-subcap:
#|   - $\mathbf{w}$
#|   - $\delta\mathbf{x}$
#|   - Xb, Xa
#|   - $[\nabla^2 J]^{-1/2}$
#| label: fig-minnorm-cost
#| layout: [[1,2],[1]]
    
    fig, ax = plt.subplots(figsize=[4,6])
    ax.plot(w,np.arange(1,w.size+1),label='cross')
    ax.plot(w_nc,np.arange(1,w.size+1),label='no cross')
    xmin,xmax = ax.get_xlim()
    xlim = max(-xmin,xmax)
    ax.set_xlim(-xlim,xlim)
    ax.legend()
    ax.set_ylabel('member')
    ax.set_xlabel('w')
    plt.show()

    fig, ax = plt.subplots(figsize=[8,6])
    ax.plot(Xb@w,label='cross')
    ax.plot(dx,ls='dashed',label='no cross')
    ymin,ymax = ax.get_ylim()
    ylim = max(-ymin,ymax)
    ax.set_ylim(-ylim,ylim)
    ax.legend()
    ax.set_xlabel('grid')
    ax.set_ylabel('dx')
    plt.show()

    fig, axs = plt.subplots(ncols=2)
    mp0=axs[0].matshow(Xb)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('Xb')
    mp1=axs[1].matshow(Xa)
    fig.colorbar(mp1,ax=axs[1],shrink=0.6,pad=0.01)
    axs[1].set_title('Xa')
    plt.show()

    fig, axs = plt.subplots(ncols=2,constrained_layout=True)
    mp0=axs[0].matshow(trans_nc)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('trans (no cross)')
    mp1=axs[1].matshow(trans)
    fig.colorbar(mp1,ax=axs[1],shrink=0.6,pad=0.01)
    axs[1].set_title('trans')
    plt.show()

```

2. regularization in state space
    $$
    \tilde{\mathbf{X}}^\mathrm{b}
    =
    \left[
        \begin{pmatrix}
        \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
        \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
        \end{pmatrix}
        +\mu\mathbf{I}
    \right]^{-1}
    \begin{pmatrix}
        \mathbf{X}^\mathrm{b}\\
        \mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    $$
    $$
    \tilde{\mathbf{d}}^\mathrm{v}
    =
    \left[
        \begin{pmatrix}
        \mathbf{P}^\mathrm{b} & \mathbf{P}^\mathrm{bv} \\
        \mathbf{P}^\mathrm{vb} & \mathbf{P}^\mathrm{v}
        \end{pmatrix}
        +\mu\mathbf{I}
    \right]^{-1}
    \begin{pmatrix}
    \mathbf{0}\\\mathbf{d}^\mathrm{v}
    \end{pmatrix}
    $$

```{python}

    mulist = [0.001,0.01,0.1]
    wlist = []
    Xalist = []
    translist = []
    for mu in mulist:
        #mu = 0.01
        Pcpi = Pc+mu*np.eye(Pc.shape[0])
        Xb_ = la.solve(Pcpi,np.vstack((Xb,Zb)))
        dv_ = la.solve(Pcpi,np.hstack((np.zeros(Xb.shape[0]),dv)))
    
        args = (Xb, Yb, Zb, do, dv, Xb_, dv_)
        w, trans = solve(*args)
        Xa = np.sqrt(nens-1)*Xb@trans
        wlist.append(w)
        Xalist.append(Xa)
        translist.append(trans)
        
        Ji = cost(np.zeros_like(w),*args)
        Jf = cost(w,*args)
        print(f"mu={mu} initial cost={Ji:.4e}")
        print(f"mu={mu} final cost={Jf:.4e}")

```

```{python}
#| fig-cap: regularized solution with $\mu$=0.1
#| fig-subcap:
#|   - $\tilde{X}^b$
#|   - $\tilde{d}^b$
#| label: fig-reg
#| layout: [[2,3],[1]]

    fig, ax = plt.subplots()
    mp=ax.matshow(Xb_)
    fig.colorbar(mp,ax=ax,pad=0.01,shrink=0.6)
    ax.set_aspect(0.5)
    plt.show()

    fig, ax = plt.subplots()
    ax.plot(dv_,np.arange(dv_.size))
    ax.set_xlabel(r'$\tilde{d}^v$')
    ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
    plt.show()
```
```{python}
#| fig-cap: regularized solution for $J$
#| fig-subcap:
#|   - $\mathbf{w}$
#|   - $\delta\mathbf{x}$
#|   - Xb, Xa
#|   - $[\nabla^2 J]^{-1/2}$
#| label: fig-reg-cost
#| layout: [[1,2],[1]]
    
    fig, ax = plt.subplots(figsize=[4,6])
    for mu, w in zip(mulist,wlist):
        ax.plot(w,np.arange(1,w.size+1),label=r'$\mu$='+f'{mu}')
    ax.plot(w_nc,np.arange(1,w.size+1),label='no cross')
    xmin,xmax = ax.get_xlim()
    xlim = max(-xmin,xmax)
    ax.set_xlim(-xlim,xlim)
    ax.legend()
    ax.set_ylabel('member')
    ax.set_xlabel('w')
    plt.show()

    fig, ax = plt.subplots(figsize=[8,6])
    for mu, w in zip(mulist,wlist):
        ax.plot(Xb@w,label=r'$\mu$='+f'{mu}')
    ax.plot(dx,ls='dashed',label='no cross')
    ymin,ymax = ax.get_ylim()
    ylim = max(-ymin,ymax)
    ax.set_ylim(-ylim,ylim)
    ax.legend()
    ax.set_xlabel('grid')
    ax.set_ylabel('dx')
    plt.show()

    fig, axs = plt.subplots(ncols=1+len(mulist),constrained_layout=True)
    mp0=axs[0].matshow(Xb)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('Xb')
    for mu, Xa in zip(mulist,Xalist):
        i=mulist.index(mu)
        mp1=axs[i+1].matshow(Xa)
        fig.colorbar(mp1,ax=axs[i+1],shrink=0.6,pad=0.01)
        axs[i+1].set_title(r'Xa, $\mu$='+f'{mu}')
    plt.show()

    fig, axs = plt.subplots(ncols=2,nrows=2,constrained_layout=True)
    mp0=axs[0,0].matshow(trans_nc)
    fig.colorbar(mp0,ax=axs[0,0],shrink=0.6,pad=0.01)
    axs[0,0].set_title('trans (no cross)')
    for mu, trans in zip(mulist,translist):
        i=mulist.index(mu)
        ax = axs.flatten()[i+1]
        mp1=ax.matshow(trans)
        fig.colorbar(mp1,ax=ax,shrink=0.6,pad=0.01)
        ax.set_title(r'trans, $\mu$='+f'{mu}')
    plt.show()

```

3. regularization in ensemble space
    
    The inverse of error covariance is replaced with the pseudo inverse.
    $$
    J(\mathbf{w})=
    \frac{K-1}{2}
    \left\{
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{bmatrix}
    \begin{pmatrix}
    \mathbf{0}\\\mathbf{d}^\mathrm{v}
    \end{pmatrix}
    -
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\\mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    \mathbf{w}
    \end{bmatrix}
    \right\}^\mathrm{T}
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{bmatrix}
    \begin{pmatrix}
    \mathbf{0}\\\mathbf{d}^\mathrm{v}
    \end{pmatrix}
    -
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\\mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    \mathbf{w}
    \end{bmatrix}
    +J_\mathrm{o}(\mathbf{w})
    \underline{+\frac{\gamma}{2}\|\mathbf{w}\|^2}
    $$

```{=tex}
\begin{align*}
    \nabla_\mathbf{w}J=
    &\begin{bmatrix}
    (K-1)\left\{
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\\mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    \right\}^\mathrm{T}
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\\mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    +(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{Y}^\mathrm{b}
    \underline{+\gamma\mathbf{I}}
    \end{bmatrix}
    \mathbf{w} \\
    &-
    (K-1)\left\{
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\\mathbf{Z}^\mathrm{b}
    \end{pmatrix}
    \right\}^\mathrm{T}
    \begin{pmatrix}
    \mathbf{X}^\mathrm{b} \\
    \mathbf{Z}^\mathrm{v}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \mathbf{0}\\\mathbf{d}^\mathrm{v}
    \end{pmatrix}
    -(\mathbf{Y}^\mathrm{b})^\mathrm{T}\mathbf{R}^{-1}\mathbf{d}^\mathrm{o}
\end{align*}
```

4. Partial least square (PLS) regression

$$
\frac{1}{K-1}
\begin{pmatrix}
\mathbf{X}^\mathrm{b} \\
\mathbf{Z}^\mathrm{v}
\end{pmatrix}
\begin{bmatrix}
(\mathbf{X}^\mathrm{b})^\mathrm{T} &
(\mathbf{Z}^\mathrm{v})^\mathrm{T}
\end{bmatrix}\tilde{\mathbf{X}}^\mathrm{b}
=
\begin{pmatrix}
    \mathbf{X}^\mathrm{b}\\
    \mathbf{Z}^\mathrm{b}
\end{pmatrix}
$$
$$
\Rightarrow \left\{
    \begin{matrix}
        \frac{1}{K-1}
        \begin{pmatrix}
            \mathbf{X}^\mathrm{b} \\
            \mathbf{Z}^\mathrm{v}
        \end{pmatrix}\tilde{\tilde{\mathbf{X}}}^\mathrm{b}=
        \begin{pmatrix}
            \mathbf{X}^\mathrm{b}\\
            \mathbf{Z}^\mathrm{b}
        \end{pmatrix} \\
        \begin{bmatrix}
        (\mathbf{X}^\mathrm{b})^\mathrm{T} &
        (\mathbf{Z}^\mathrm{v})^\mathrm{T}
        \end{bmatrix}\tilde{\mathbf{X}}^\mathrm{b}=\tilde{\tilde{\mathbf{X}}}^\mathrm{b}
    \end{matrix}
\right.
$$

$$
\frac{1}{K-1}
\begin{pmatrix}
\mathbf{X}^\mathrm{b} \\
\mathbf{Z}^\mathrm{v}
\end{pmatrix}
\begin{bmatrix}
(\mathbf{X}^\mathrm{b})^\mathrm{T} &
(\mathbf{Z}^\mathrm{v})^\mathrm{T}
\end{bmatrix}\tilde{\mathbf{d}}^\mathrm{v}
=
\begin{pmatrix}
\mathbf{0}\\\mathbf{d}^\mathrm{v}
\end{pmatrix}
$$
$$
\Rightarrow \left\{
    \begin{matrix}
        \frac{1}{K-1}
        \begin{pmatrix}
            \mathbf{X}^\mathrm{b} \\
            \mathbf{Z}^\mathrm{v}
        \end{pmatrix}\tilde{\tilde{\mathbf{d}}}^\mathrm{v}=
        \begin{pmatrix}
        \mathbf{0}\\\mathbf{d}^\mathrm{v}
        \end{pmatrix} \\
        \begin{bmatrix}
        (\mathbf{X}^\mathrm{b})^\mathrm{T} &
        (\mathbf{Z}^\mathrm{v})^\mathrm{T}
        \end{bmatrix}\tilde{\mathbf{d}}^\mathrm{v}=\tilde{\tilde{\mathbf{d}}}^\mathrm{v}
    \end{matrix}
\right.
$$

```{python}

    from sklearn.cross_decomposition import PLSRegression

    nclist = [20,40,60]
    wlist = []
    Xalist = []
    translist = []
    for nc in nclist:
        pls1 = PLSRegression(n_components=nc)
        pls1.fit(Pc,np.hstack((np.zeros(Xb.shape[0]),dv)))
        dv_ = pls1.coef_[0,:]
        print(dv_.shape)
        pls2 = PLSRegression(n_components=nc)
        pls2.fit(Pc,np.vstack((Xb,Zb)))
        Xb_ = pls2.coef_.T
        print(Xb_.shape)
        print(f"nc={nc} pls1.score={pls1.score(Pc,np.hstack((np.zeros(Xb.shape[0]),dv)))}")
        print(f"nc={nc} pls2.score={pls2.score(Pc,np.vstack((Xb,Zb)))}")

        args = (Xb, Yb, Zb, do, dv, Xb_, dv_)
        w, trans = solve(*args)
        Xa = np.sqrt(nens-1)*Xb@trans
        wlist.append(w)
        Xalist.append(Xa)
        translist.append(trans)
        
        Ji = cost(np.zeros_like(w),*args)
        Jf = cost(w,*args)
        print(f"nc={nc} initial cost={Ji:.4e}")
        print(f"nc={nc} final cost={Jf:.4e}")

```

```{python}
#| fig-cap: PLS solution with 40 PCA modes
#| fig-subcap:
#|   - $\tilde{X}^b$
#|   - $\tilde{d}^b$
#| label: fig-pls
#| layout: [[2,3],[1]]

    fig, ax = plt.subplots()
    mp=ax.matshow(Xb_)
    fig.colorbar(mp,ax=ax,pad=0.01,shrink=0.6)
    ax.set_aspect(0.5)
    plt.show()

    fig, ax = plt.subplots()
    ax.plot(dv_,np.arange(dv_.size))
    ax.set_xlabel(r'$\tilde{d}^v$')
    ax.vlines([0],0,1,colors='gray',transform=ax.get_xaxis_transform())
    plt.show()
```
```{python}
#| fig-cap: PLS solution for $J$
#| fig-subcap:
#|   - $\mathbf{w}$
#|   - $\delta\mathbf{x}$
#|   - Xb, Xa
#|   - $[\nabla^2 J]^{-1/2}$
#| label: fig-pls-cost
#| layout: [[1,2],[1]]
    
    fig, ax = plt.subplots(figsize=[4,6])
    for nc, w in zip(nclist,wlist):
        ax.plot(w,np.arange(1,w.size+1),label=f'nc={nc}')
    ax.plot(w_nc,np.arange(1,w.size+1),label='no cross')
    xmin,xmax = ax.get_xlim()
    xlim = max(-xmin,xmax)
    ax.set_xlim(-xlim,xlim)
    ax.legend()
    ax.set_ylabel('member')
    ax.set_xlabel('w')
    plt.show()

    fig, ax = plt.subplots(figsize=[8,6])
    for nc, w in zip(nclist,wlist):
        ax.plot(Xb@w,label=f'nc={nc}')
    ax.plot(dx,ls='dashed',label='no cross')
    ymin,ymax = ax.get_ylim()
    ylim = max(-ymin,ymax)
    ax.set_ylim(-ylim,ylim)
    ax.legend()
    ax.set_xlabel('grid')
    ax.set_ylabel('dx')
    plt.show()

    fig, axs = plt.subplots(ncols=1+len(mulist),constrained_layout=True)
    mp0=axs[0].matshow(Xb)
    fig.colorbar(mp0,ax=axs[0],shrink=0.6,pad=0.01)
    axs[0].set_title('Xb')
    for nc, Xa in zip(nclist,Xalist):
        i=nclist.index(nc)
        mp1=axs[i+1].matshow(Xa)
        fig.colorbar(mp1,ax=axs[i+1],shrink=0.6,pad=0.01)
        axs[i+1].set_title(f'Xa, nc={nc}')
    plt.show()

    fig, axs = plt.subplots(ncols=2,nrows=2,constrained_layout=True)
    mp0=axs[0,0].matshow(trans_nc)
    fig.colorbar(mp0,ax=axs[0,0],shrink=0.6,pad=0.01)
    axs[0,0].set_title('trans (no cross)')
    for nc, trans in zip(nclist,translist):
        i=nclist.index(nc)
        ax = axs.flatten()[i+1]
        mp1=ax.matshow(trans)
        fig.colorbar(mp1,ax=ax,shrink=0.6,pad=0.01)
        ax.set_title(f'trans, nc={nc}')
    plt.show()

```
